{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review: https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "#import webbrowser\n",
    "\n",
    "def get_soup(url):\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0'}\n",
    "\n",
    "    r = s.get(url, headers=headers)\n",
    "\n",
    "    #with open('temp.html', 'wb') as f:\n",
    "    #    f.write(r.content)\n",
    "    #    webbrowser.open('temp.html')\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print('status code:', r.status_code)\n",
    "    else:\n",
    "        return BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "def parse(url, response):\n",
    "\n",
    "    if not response:\n",
    "        print('no response:', url)\n",
    "        return\n",
    "\n",
    "    # get number of reviews\n",
    "    num_reviews = response.find('span', class_='reviews_header_count').text\n",
    "    num_reviews = num_reviews[1:-1] # remove `( )`\n",
    "    num_reviews = num_reviews.replace(',', '') # remove `,`\n",
    "    num_reviews = int(num_reviews)\n",
    "    print('num_reviews:', num_reviews, type(num_reviews))\n",
    "\n",
    "    # create template for urls to pages with reviews\n",
    "    url = url.replace('.html', '-or{}.html')\n",
    "    print('template:', url)\n",
    "\n",
    "    # load pages with reviews\n",
    "    for offset in range(0, num_reviews, 5):\n",
    "        print('url:', url.format(offset))\n",
    "        url_ = url.format(offset)\n",
    "        parse_reviews(url_, get_soup(url_))\n",
    "        return # for test only - to stop after first page\n",
    "\n",
    "def parse_reviews(url, response):\n",
    "    print('review:', url)\n",
    "\n",
    "    if not response:\n",
    "        print('no response:', url)\n",
    "        return\n",
    "\n",
    "    # get every review\n",
    "    for idx, review in enumerate(response.find_all('div', class_='review-container')):\n",
    "        item = {\n",
    "            'hotel_name': response.find('h1', class_='heading_title').text,\n",
    "            'review_title': review.find('span', class_='noQuotes').text,\n",
    "            'review_body': review.find('p', class_='partial_entry').text,\n",
    "            'review_date': review.find('span', class_='relativeDate')['title'],#.text,#[idx],\n",
    "            'num_reviews_reviewer': review.find('span', class_='badgetext').text,\n",
    "            'reviewer_name': review.find('span', class_='scrname').text,\n",
    "            'bubble_rating': review.select_one('div.reviewItemInline span.ui_bubble_rating')['class'][1][7:],\n",
    "        }\n",
    "\n",
    "        results.append(item) # <--- add to global list\n",
    "\n",
    "        #~ yield item\n",
    "        for key,val in item.items():\n",
    "            print(key, ':', val)\n",
    "        print('----')\n",
    "        # return for test only - to stop after first review\n",
    "\n",
    "\n",
    "# --- main ---\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "start_urls = [\n",
    "    'https://www.tripadvisor.com/Hotel_Review-g562819-d289642-Reviews-Hotel_Caserio-Playa_del_Ingles_Maspalomas_Gran_Canaria_Canary_Islands.html',\n",
    "    #https://www.tripadvisor.com/Hotel_Review-g60795-d102542-Reviews-Courtyard_Philadelphia_Airport-Philadelphia_Pennsylvania.html',\n",
    "    #'https://www.tripadvisor.com/Hotel_Review-g60795-d122332-Reviews-The_Ritz_Carlton_Philadelphia-Philadelphia_Pennsylvania.html',\n",
    "]\n",
    "\n",
    "#results = [] # <--- global list for items\n",
    "\n",
    "for url in start_urls:\n",
    "    #response=get_soup(url)\n",
    "    parse_reviews(url, get_soup(url))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results) # <--- convert list to DataFrame\n",
    "#df.to_csv('output.csv')    # <--- save in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
